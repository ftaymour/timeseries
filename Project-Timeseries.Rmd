---
title: "Project"
author: "Farbod Taymouri"
output:
  html_document:
    df_print: paged
    toc: yes
  pdf_document:
    number_sections: yes
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

The following libraries will be used in this project.

```{r,message=FALSE, warning=FALSE}
library(astsa)
library(ggplot2)
library(forecast)
library(dynlm)
library(xts)
library(corrplot)
library(psych)
```
# Dataset description
The dataset used in this project is about [Appliances energy prediction Data Set](https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction) that is available on UCI website. The data set is at 10 min for about 4.5 months. The house temperature and humidity conditions were monitored with a ZigBee wireless sensor network. Each wireless node transmitted the temperature and humidity conditions around 3.3 min. Then, the wireless data was averaged for 10 minutes periods. The energy data was logged every 10 minutes with m-bus energy meters. Weather from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis (rp5.ru), and merged together with the experimental data sets using the date and time column. Two random variables have been included in the data set for testing the regression models and to filter out non predictive attributes (parameters). 

## Attributes
The following attributes are used in this dataset:

* date time year-month-day hour:minute:second
+ Appliances, energy use in Wh
+ lights, energy use of light fixtures in the house in Wh
+ T1, Temperature in kitchen area, in Celsius
+ RH_1, Humidity in kitchen area, in %
+ T2, Temperature in living room area, in Celsius
+ RH_2, Humidity in living room area, in %
+ T3, Temperature in laundry room area
+ RH_3, Humidity in laundry room area, in %
+ T4, Temperature in office room, in Celsius
+ RH_4, Humidity in office room, in %
+ T5, Temperature in bathroom, in Celsius
+ RH_5, Humidity in bathroom, in %
+ T6, Temperature outside the building (north side), in Celsius
+ RH_6, Humidity outside the building (north side), in %
+ T7, Temperature in ironing room , in Celsius
+ RH_7, Humidity in ironing room, in %
+ T8, Temperature in teenager room 2, in Celsius
+ RH_8, Humidity in teenager room 2, in %
+ T9, Temperature in parents room, in Celsius
+ RH_9, Humidity in parents room, in %
+ To, Temperature outside (from Chievres weather station), in Celsius
+ Pressure (from Chievres weather station), in mm Hg
+ RH_out, Humidity outside (from Chievres weather station), in %
+ Wind speed (from Chievres weather station), in m/s
+ Visibility (from Chievres weather station), in km
+ Tdewpoint (from Chievres weather station), Â°C
+ rv1, Random variable 1, nondimensional
+ rv2, Random variable 2, nondimensional 

## Problem Definition and Methodology
The dataset as demonstrated above contains multi timeseres variables that can be used for the prediction of the target variable, i.e., Appliance. However, in this project the focus will be pain on analysing some timeseries features to demonstrate the learned lessons from this course.

# Basic Data Analysis
First of all data must be fetched and changed to the timeseres datatype. Since the data is stored in a CSV file, we read it by the standard function and then convert it to TS or XTS.  __It must be mentioned that there is no missing values in this dataset__, as shown bellow:

```{r, message=FALSE, warning=FALSE}
#Reading Data
energy=read.csv(file= "C:/Users/taymouri/Desktop/Indiana/Timeseries/Project/energydata_complete.csv", header=TRUE, sep=",")
#checking NA
sum(is.na(energy))
#Converting to XTS
energy_xts=xts(energy[,-1], order.by =  as.POSIXct(energy$date, format="%Y-%m-%d %H:%M:%S", tz="GMT"))
#Head of the dataset (for the sake of represenation only for some features are shown)
head(energy_xts[,3:7])
#Tail of the dataset
tail(energy_xts[,3:7])
```

We can look at some basic information about the timeseries data, like frequency, number of days and etc.

```{r}
#Number of years
nyears(energy_xts)

#Number of mounths
nmonths(energy_xts)

#Number of days
ndays(energy_xts)

#Frequency
periodicity(energy_xts)
```
## Corrologram
It would be interesting to look at the correlation plots between variables. "corrplot ()" is very usefull to give a nice visualization about the correlation between variables.
```{r}
corrplot(cor(energy_xts), type="upper")
```
The above plot shows the existing positive and negative correaltions among the variables. For example there is a negative correlation between RH_6 (humidity outside the home) and T7 (tempreture in ironing room). This plot shows us the way that values of two variables change against each other, i.e., positive or negative.


## Boxplot
The following boxplot shows the distribution values of T7 over existing cycles
```{r}
#Creating a ts object, we set the frequency to 30, such that box plots shows the distributions per day
T7.ts=ts(coredata(energy_xts[,which(names(energy_xts) == "T7")]), start=1, frequency = 30)
boxplot(T7.ts ~ cycle(T7.ts))
```

## Histogram
One way to identify whether a timeseries is stationary, is to look at its histogram. Usually bell-shaped histograms can be regarded as stationary processes, whereas skewed distrobutions show non-stationary processes.

```{r}
#Excluding the last two columns since they are not timesereis
multi.hist(energy_xts[,!names(energy_xts) %in% c('rv1', 'rv2')])
```
As the above plot shows most of timeseries variables except __Windspeed, RH_out__ are stationary.

## Decomposition
A timeseries can be decomposed into three main elements, i.e., trend, seasonal and residuals. We selected "T7" for this issue (since "decompose()" does not work with XTS objects, a "ts" object is created first).
```{r}
#Creating a ts object (In every month we have (30*24*60)/10 = 4320 samples
T7.ts=ts(coredata(energy_xts[,which(names(energy_xts) == "T7")]), start=1, frequency = 4320)
#decomposing
plot(decompose(T7.ts))
```
As the above plot shows, trend is increasing as it is supposed to be, since the observations are sampled from January until May. The seasonal plot clearly depicts cycles in each month. More importantly, one can see that the ransom noise is fully captured by this decomposition.

## Smoohting
Also we can smootht this timeseries by different methods to see the underlying trend. The locally-weighted polynomial regression (lowess) will be invoked for this matter.

```{r}
#Smoohting using Lowess for T7
T7.lowess=lowess(energy_xts[,which(names(energy_xts) == "T7")])
#Plotting the time series and its trend
ggplot(data=data.frame(real=coredata(energy_xts[,15])[,1], smooth = T7.lowess$y, 
                       time= time(energy_xts[,15])))+
  geom_line(aes(x=time, y=real), col="black") + geom_line(aes(x=time, y=smooth), col="red")

```
The result shows an upward trend for the variable T7 (temprature in ironing room), which is not a surprising fact since the timeseries is captured from spring to summer.



## Linear Regression
Also, the linear trend could be obtained via linear regression as follows. It must be mentioned a "ts" object must be created first, since an XTS object does not work well in this case.

```{r, message=FALSE, warning=FALSE}
#Creating a "ts" object for T7
T7.ts= ts(coredata(energy_xts[,which(names(energy_xts) == "T7")])[,1], start=1)
#Regression with intercept
fit.linear=lm(T7.ts ~ time(T7.ts))
#summary of the model
summary(fit.linear)
#Plot linear trend
ggplot(data=data.frame(real=T7.ts, fit=fit.linear$fitted.values, time = time(energy_xts[,15])))+
  geom_line(aes(x=time, y=real), col="black") + geom_line(aes(x=time, y=fit), col="blue")
```
The esimtated coffeicient for the time, tells that in each 10 minutes there is an increase amount of temprature, i.e.,  $3.092e-04$ in the unit of measurement.

# Stationarity
All the previous plots of T7 showed an upward trend which presumably implies that this timeseries is not stationary, i.e., corresponding characteristics changing over time. Hence, it must be fixed in some ways. It can be done by log transformation or by differencing.

## Transformation
The following codes transfomr T7 into logarithmic and reciprocal values.

```{r}
#Creating logarithmic and reciprocal transformations
T7.log=log(energy_xts[,which(names(energy_xts) == "T7")] )
T7.recip = 1/energy_xts[,which(names(energy_xts) == "T7")]

#Merging timeseries into a single object
T7.transform=merge.xts(T7.log, T7.recip, energy_xts[,which(names(energy_xts) == "T7")])
#Providing column names
colnames(T7.transform) = c('log', 'reciprocal', 'original')
#Plotting
autoplot(T7.transform)

```
It is clear from the figures that both transformations can make the timeseries more stabilize in terms of existing variations. From the figures the reciprocal and logarithmic transformations look like a horizontal line but it is owing to inappropriate scalling that occurred when three figures are packed into one. Also, it must be stressed that due to absence of zero and negative values the mentioned transfomations did work.


Adjusting the correct value of differencing for a timeseries is a brute force task and there is no shortcuts. In this part, first order differencing will be adopted to see how it improves the stationary property of a given timeseries.

```{r, message=FALSE, warning=FALSE}
#Creating a first order differencing timeseries
T7.diff1=diff(energy_xts[,which(names(energy_xts) == "T7")])
#Plotting
autoplot(T7.diff1)+ylab("T7.diff1")
```
The above plot shows clearly that the first order differencing (d=1) can capture the existing linear trend and makes the a stationary timeseries. This results also confirmes the output of linear regression obtined earlier, since the linear regression captures the first order linear trend of a timeseries.

# Model Diagnostic and Selection

A timeseries can be modeled through different formulations, including Moving Average (MA), Auto Regresive (AR), AutoRegressive Moving Average (ARMA) and AutoRegressive Integrated Moving Average (ARIMA). Before getting into the details it would be helpful to investigate Autocorrelation Function (ACF) and Partially Autocorrelation Function (PACF) plots. These plots guide us which model better fits the data under consideration.

## ACF and PACF
This part continues the investigation for timeseries "T7". The following shows corresponding ACF and PACF for this variable.
```{r,message=FALSE, warning=FALSE, results = 'hide'}
#Plotting ACF and PACF for T7
acf2(energy_xts[,which(names(energy_xts) == "T7")])
```
These plots can help us to select the right model's form. Indeed, MA processes have an ACF plot that is __cut off__ whereas for AR and ARMA processes it is __tailed off__. On the other side PACF can provide a distinction between ARMA and AR, where, for the former the plot is tailed off and for the later it is cut off. From the above plot, It is suspected that the model's form is ARMA since the PACF dosen't show a clear cut off. We can check this issue in another way using AIC infomration criterion. The aim is to build some models and the compares corresponding AIC values.

## Model Selection
In this section, different models will be created and compared in terms of AIC values.
```{r}
#Creating different models
#First order AR
AR1=arima(energy_xts[,which(names(energy_xts) == "T7")], order=c(1,0,0) )
#First order MA
MA1=arima(energy_xts[,which(names(energy_xts) == "T7")], order=c(0,0,1) )
#ARMA(1,0,1)
ARMA=arima(energy_xts[,which(names(energy_xts) == "T7")], order=c(1,0,1) )
#ARIMA(1,1,0)
ARIMA=arima(energy_xts[,which(names(energy_xts) == "T7")], order=c(1,1,0) )

#Comparing AIC values
print(cat("AIC for different models:\n", "AR1:",round(AIC(AR1),2), "\n MA1:",round(AIC(MA1),2), 
            "\n ARMA:", round(AIC(ARMA),2), "\n ARIMA:", round(AIC(ARIMA),2) ))
```

As shown by AIC values above, ARIMA has better ability to fit data (smaller AIC value), but instead of finding the parameters of this model in an exhaustive way, we can resort to "Auto.arima()" function that returns the most fitting model.
```{r}
#Fitting the best model 
Best.fit=auto.arima(energy_xts[,which(names(energy_xts) == "T7")])
Best.fit
AIC(Best.fit)
```

The above results indicate the form and parameters of the mnodel which is ARIMA(1,1,1), i.e., first order difference - autoregressive - moving average. Also, one could note that the reported AIC value is smaller than other AIC values obtained earlier.




# Including Plots

## plotting

```{r pressure, message=FALSE, warning=FALSE}
w=rnorm(500,0,1)
v= filter(w, filter = rep(1/3, 3))


ggplot(data =data.frame(d=w, time= seq(1,length(w)) )) + geom_line(aes(x=time, y=d))
ggplot(data =data.frame(d=v, time= seq(1,length(v)) )) + geom_line(aes(x=time, y=d))
```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


